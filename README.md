# Wordtyle - Korean Writing Style Embedding Model Trainer

![Python](https://img.shields.io/badge/python-v3.8+-blue.svg)
![PyTorch](https://img.shields.io/badge/PyTorch-v2.0+-orange.svg)
![License](https://img.shields.io/badge/license-AGPL%20v3-green.svg)

Wordtyle is a deep learning tool for training Korean writing style embedding models. It analyzes text writing styles and converts them into embedding vectors. With its user-friendly Gradio-based web interface, anyone can easily create writing style analysis models.

## âœ¨ Key Features

- ğŸ“š **Book Text-based Training**: Upload text files (novels, essays, etc.) to train writing style analysis models
- ğŸ¯ **8 Writing Style Classifications**: Automatic classification of formal, informal, literary, dialogue, narrative, poetic, technical, and emotional styles
- ğŸš€ **GPU Acceleration Support**: High-speed training with CUDA, XFormers, and Flash Attention 2
- ğŸ¨ **Intuitive Web Interface**: Easy-to-use Gradio-based GUI
- ğŸ’¾ **Model Saving & Reusability**: Save trained models and load them for later use
- ğŸ§ª **Real-time Testing**: Instantly test text style analysis after training completion

## ğŸ› ï¸ Installation

### 1. Clone the Repository

```bash
git clone https://github.com/yourusername/wordtyle.git
cd wordtyle
```

### 2. Create Virtual Environment

```bash
python -3.12 -m venv venv

# Windows
venv\Scripts\activate

# macOS/Linux
source venv/bin/activate
```

### 3. Install Dependencies

#### Basic Installation (CPU only)
```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
pip install -r requirements.txt
```

#### GPU Installation (Recommended)
```bash
# Install PyTorch with CUDA support
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128

# Install basic requirements
pip install -r requirements.txt

# Optional: Install acceleration libraries
pip install xformers>=0.0.20  # Memory optimization
pip install triton>=2.0.0     # CUDA kernel optimization
pip install flash-attn>=2.0.0 # Flash Attention 2
```

## ğŸš€ Quick Start

### 1. Launch the Application

```bash
python main.py
```

Or use the batch file on Windows:
```bash
run_gpu.bat
```

### 2. Access the Web Interface

Open your browser and navigate to:
```
http://localhost:7860
```

### 3. Train Your Model

1. **ğŸ“š Data Preparation Tab**:
   - Upload a Korean text file (.txt)
   - Set minimum sentence length (recommended: 20+ characters)
   - Click "ğŸ“Š Analyze File"

2. **ğŸ‹ï¸ Model Training Tab**:
   - Configure training parameters:
     - Base model (default: klue/bert-base)
     - Number of epochs (1-10)
     - Batch size (adjust based on your GPU memory)
     - Learning rate (default: 2e-5)
     - Embedding dimension (128-768)
   - Click "ğŸš€ Start Training"

3. **ğŸ§ª Model Testing Tab**:
   - Enter test text to analyze writing style
   - View style probability distributions
   - Get embedding vectors

## ğŸ“Š Writing Style Categories

The model classifies text into 8 different Korean writing styles:

| Style | Korean | Description | Example Patterns |
|-------|--------|-------------|------------------|
| **Formal** | ê²©ì‹ì²´ | Formal/polite language | ìŠµë‹ˆë‹¤, ì…ë‹ˆë‹¤, í•˜ì˜€ìŠµë‹ˆë‹¤ |
| **Informal** | ë¹„ê²©ì‹ì²´ | Casual/informal language | ì•¼, ì–´, ì§€, ì–ì•„, ê±°ì•¼ |
| **Literary** | ë¬¸í•™ì  | Literary/artistic style | ì²˜ëŸ¼, ë§ˆì¹˜, ë“¯ì´, ê²ƒë§Œ ê°™ì•˜ë‹¤ |
| **Dialogue** | ëŒ€í™”ì²´ | Conversational style | ", ', ë¼ê³ , í–ˆë‹¤, ë§í–ˆë‹¤ |
| **Narrative** | ì„œìˆ ì²´ | Narrative/descriptive | ê·¸ëŠ”, ê·¸ë…€ëŠ”, ì´ë•Œ, ê·¸ ìˆœê°„ |
| **Poetic** | ì‹œì  | Poetic/lyrical style | ë‹¬ë¹›, ë°”ëŒ, ê½ƒì, ë³„, êµ¬ë¦„ |
| **Technical** | ê¸°ìˆ ì  | Technical/analytical | ì‹œìŠ¤í…œ, ë°ì´í„°, ë¶„ì„, ê²°ê³¼ |
| **Emotional** | ê°ì„±ì  | Emotional/expressive | ê°€ìŠ´, ë§ˆìŒ, ëˆˆë¬¼, ê¸°ì¨, ìŠ¬í”” |

## ğŸ”§ Configuration

### Model Parameters

- **Base Model**: Choose from pre-trained Korean language models
  - `klue/bert-base` (default)
  - `klue/roberta-base`
  - `beomi/KcELECTRA-base`
  - `monologg/kobert`

- **Training Parameters**:
  - Epochs: 1-10 (default: 3)
  - Batch Size: 4-64 (adjust based on GPU memory)
  - Learning Rate: 1e-6 to 1e-4 (default: 2e-5)
  - Embedding Dimension: 128-768 (default: 384)

### Hardware Requirements

#### Minimum Requirements
- **CPU**: 4 cores
- **RAM**: 8GB
- **Storage**: 2GB free space

#### Recommended Requirements
- **GPU**: NVIDIA GPU with 8GB+ VRAM
- **CPU**: 8+ cores
- **RAM**: 16GB+
- **Storage**: 5GB+ free space

### Performance Optimization

The application automatically detects and uses available acceleration libraries:

- âœ… **CUDA**: GPU acceleration
- âœ… **XFormers**: Memory-efficient attention
- âœ… **Flash Attention 2**: Faster attention computation
- âœ… **Mixed Precision**: Reduced memory usage

## ğŸ“ Project Structure

```
wordtyle/
â”œâ”€â”€ main.py              # Main application file
â”œâ”€â”€ requirements.txt     # Python dependencies
â”œâ”€â”€ run_gpu.bat         # Windows batch file for easy execution
â”œâ”€â”€ README.md           # This file
â”œâ”€â”€ style_models/       # Directory for saved models
â”œâ”€â”€ example/            # Example files and demos
â””â”€â”€ venv/              # Virtual environment (after setup)
```

## ğŸ¯ Usage Examples

### Basic Training Example

```python
from main import StyleEmbeddingTrainer

# Initialize trainer
trainer = StyleEmbeddingTrainer(model_name="klue/bert-base")

# Load your book text
with open("my_novel.txt", "r", encoding="utf-8") as f:
    book_text = f.read()

# Prepare data and train
data_dict = trainer.prepare_data(book_text)
trainer.create_model(embedding_dim=384)
history = trainer.train_model(data_dict, num_epochs=3)

# Save the model
model_path = trainer.save_model("my_style_model")
```

### Extract Embeddings

```python
# Extract style embeddings from text
texts = ["ê·¸ëŠ” ì¡°ìš©íˆ ë¬¸ì„ ì—´ê³  ë°© ì•ˆìœ¼ë¡œ ë“¤ì–´ê°”ë‹¤.", 
         "ì•¼, ë­í•˜ê³  ìˆì–´?"]
embeddings = trainer.extract_embeddings(texts)
print(f"Embedding shape: {embeddings.shape}")
```

## ğŸ” Troubleshooting

### Common Issues

1. **Buttons not responding**
   - Check browser console (F12) for errors
   - Make sure to click "ğŸ“Š Analyze File" after uploading

2. **Out of memory errors**
   - Reduce batch size (try 4-8 for CPU, 8-16 for GPU)
   - Reduce embedding dimension
   - Use smaller text files

3. **Slow training**
   - Install GPU acceleration libraries
   - Increase batch size if memory allows
   - Use smaller models (bert-base instead of bert-large)

4. **Import errors**
   - Make sure virtual environment is activated
   - Reinstall requirements: `pip install -r requirements.txt`
   - For GPU: Install PyTorch with CUDA support

### Performance Tips

- **For CPU training**: Use batch size 4-8, embedding dim 256
- **For GPU training**: Use batch size 16-32, embedding dim 384-512
- **Text size**: Minimum 10,000 characters recommended for good results
- **Sentence length**: Set minimum 20 characters for quality data

## ğŸ¤ Contributing

We welcome contributions! Please follow these steps:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

### Development Setup

```bash
git clone https://github.com/yourusername/wordtyle.git
cd wordtyle
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate on Windows
pip install -r requirements.txt
pip install -e .
```

## ğŸ“„ License

This project is licensed under the GNU Affero General Public License v3.0 (AGPL-3.0).

This means:
- âœ… You can use, modify, and distribute this software
- âœ… You can use it for commercial purposes
- â— If you run this software on a server and provide it as a service, you must make the source code available to users
- â— Any modifications must also be licensed under AGPL-3.0
- â— You must include the original license and copyright notice

See the [LICENSE](LICENSE) file for full details.

## ğŸ™ Acknowledgments

- [Hugging Face Transformers](https://huggingface.co/transformers/) for the transformer models
- [KLUE](https://klue-benchmark.com/) for Korean language understanding models
- [Gradio](https://gradio.app/) for the web interface framework
- [PyTorch](https://pytorch.org/) for the deep learning framework

## ğŸ“ Support

- ğŸ› **Bug Reports**: [Open an issue](https://github.com/yourusername/wordtyle/issues)
- ğŸ’¡ **Feature Requests**: [Open an issue](https://github.com/yourusername/wordtyle/issues)
- ğŸ’¬ **Discussions**: [GitHub Discussions](https://github.com/yourusername/wordtyle/discussions)

## ğŸ”— Related Projects

- [KoBERT](https://github.com/SKTBrain/KoBERT): Korean BERT model
- [Sentence Transformers](https://www.sbert.net/): Sentence embedding models
- [KLUE](https://github.com/KLUE-benchmark/KLUE): Korean Language Understanding Evaluation

---

Made with â¤ï¸ for the Korean NLP community
